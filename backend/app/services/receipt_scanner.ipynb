{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-28 01:54:48,567 - INFO - Extracting text from ../../data/forms/1040-NR.pdf\n",
      "2025-02-28 01:54:48,573 - ERROR - Local PDF processing failed: Unable to get page count. Is poppler installed and in PATH?\n",
      "2025-02-28 01:54:48,575 - ERROR - Error extracting text from PDF: Unable to get page count. Is poppler installed and in PATH?\n",
      "2025-02-28 01:54:48,577 - WARNING - No text extracted from ../../data/forms/1040-NR.pdf\n",
      "2025-02-28 01:54:48,622 - INFO - Successfully connected to Google Cloud Document AI\n",
      "2025-02-28 01:54:48,624 - INFO - Extracting text from ../../data/forms/1040-NR.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-28 01:54:49,972 - ERROR - Google Cloud Document AI processing failed: 401 Request had invalid authentication credentials. Expected OAuth 2 access token, login cookie or other valid authentication credential. See https://developers.google.com/identity/sign-in/web/devconsole-project. [reason: \"ACCESS_TOKEN_EXPIRED\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"documentai.googleapis.com\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"method\"\n",
      "  value: \"google.cloud.documentai.v1.DocumentProcessorService.ProcessDocument\"\n",
      "}\n",
      "]\n",
      "2025-02-28 01:54:49,973 - ERROR - Error extracting text from PDF: 401 Request had invalid authentication credentials. Expected OAuth 2 access token, login cookie or other valid authentication credential. See https://developers.google.com/identity/sign-in/web/devconsole-project. [reason: \"ACCESS_TOKEN_EXPIRED\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"documentai.googleapis.com\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"method\"\n",
      "  value: \"google.cloud.documentai.v1.DocumentProcessorService.ProcessDocument\"\n",
      "}\n",
      "]\n",
      "2025-02-28 01:54:49,974 - WARNING - No text extracted from ../../data/forms/1040-NR.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import uuid\n",
    "import re\n",
    "import pandas as pd\n",
    "from typing import Dict, Any, Optional, List\n",
    "import logging\n",
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "from google.cloud import documentai\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Define deduction policies\n",
    "deduction_policies = {\n",
    "    \"deductions\": [\n",
    "        {\"category\": \"Home Office\", \"rate\": 0.30, \"max_limit\": 5000},\n",
    "        {\"category\": \"Software & Subscriptions\", \"rate\": 0.50, \"max_limit\": 3000},\n",
    "        {\"category\": \"Freelancer Platform Fees\", \"rate\": 0.25, \"max_limit\": 2000},\n",
    "        {\"category\": \"Work Equipment\", \"rate\": 0.50, \"max_limit\": 5000},\n",
    "        {\"category\": \"Internet & Phone\", \"rate\": 0.40, \"max_limit\": 2500},\n",
    "        {\"category\": \"Education & Training\", \"rate\": 1.0, \"max_limit\": 5000},\n",
    "        {\"category\": \"Business Travel\", \"rate\": 1.0, \"max_limit\": 10000},\n",
    "        {\"category\": \"Client Entertainment\", \"rate\": 0.20, \"max_limit\": 1500},\n",
    "        {\"category\": \"Office Supplies\", \"rate\": 1.0, \"max_limit\": 5000},\n",
    "        {\"category\": \"Software & Tools\", \"rate\": 1.0, \"max_limit\": 10000},\n",
    "        {\"category\": \"Meals & Entertainment\", \"rate\": 0.5, \"max_limit\": 2000},\n",
    "        {\"category\": \"Rent & Utilities\", \"rate\": 1.0, \"max_limit\": 15000},\n",
    "        {\"category\": \"Marketing & Advertising\", \"rate\": 1.0, \"max_limit\": 10000},\n",
    "        {\"category\": \"Transportation\", \"rate\": 1.0, \"max_limit\": 5000},\n",
    "        {\"category\": \"Healthcare\", \"rate\": 0.0, \"max_limit\": 0},\n",
    "        {\"category\": \"Personal Shopping\", \"rate\": 0.0, \"max_limit\": 0},\n",
    "        {\"category\": \"Groceries\", \"rate\": 0.0, \"max_limit\": 0}\n",
    "    ]\n",
    "}\n",
    "\n",
    "class ReceiptProcessor:\n",
    "    def __init__(self, use_google_cloud: bool = False, credentials_path: Optional[str] = None, \n",
    "                 project_id: Optional[str] = None, processor_id: Optional[str] = None, \n",
    "                 location: str = \"us\"):\n",
    "\n",
    "        self.use_google_cloud = use_google_cloud\n",
    "        \n",
    "        if use_google_cloud:\n",
    "            if not all([credentials_path, project_id, processor_id]):\n",
    "                raise ValueError(\"To use Google Cloud, you must provide credentials_path, project_id, and processor_id\")\n",
    "            \n",
    "            self.project_id = project_id\n",
    "            self.processor_id = processor_id\n",
    "            self.location = location\n",
    "            self.processor_name = f\"projects/{project_id}/locations/{location}/processors/{processor_id}\"\n",
    "            \n",
    "            try:\n",
    "                self.credentials = service_account.Credentials.from_service_account_file(credentials_path)\n",
    "                self.client = documentai.DocumentProcessorServiceClient(credentials=self.credentials)\n",
    "                logging.info(\"Successfully connected to Google Cloud Document AI\")\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Failed to initialize Google Cloud Document AI: {e}\")\n",
    "                raise\n",
    "    \n",
    "    def extract_text_from_pdf(self, pdf_path: str) -> str:\n",
    "  \n",
    "        if not os.path.exists(pdf_path):\n",
    "            raise FileNotFoundError(f\"PDF file not found: {pdf_path}\")\n",
    "        \n",
    "        logging.info(f\"Extracting text from {pdf_path}\")\n",
    "        \n",
    "        try:\n",
    "            if self.use_google_cloud:\n",
    "                return self._extract_text_using_google(pdf_path)\n",
    "            else:\n",
    "                return self._extract_text_locally(pdf_path)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error extracting text from PDF: {e}\")\n",
    "            return \"\"\n",
    "    \n",
    "    def _extract_text_using_google(self, pdf_path: str) -> str:\n",
    "        \"\"\"Use Google Cloud Document AI to extract text from PDF.\"\"\"\n",
    "        try:\n",
    "            with open(pdf_path, \"rb\") as pdf_file:\n",
    "                pdf_content = pdf_file.read()\n",
    "            \n",
    "            raw_document = documentai.RawDocument(content=pdf_content, mime_type=\"application/pdf\")\n",
    "            request = documentai.ProcessRequest(name=self.processor_name, raw_document=raw_document)\n",
    "            result = self.client.process_document(request=request)\n",
    "            \n",
    "            return result.document.text if result.document.text else \"\"\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Google Cloud Document AI processing failed: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def _extract_text_locally(self, pdf_path: str) -> str:\n",
    "        \"\"\"Use local tools (pdf2image + tesseract) to extract text from PDF.\"\"\"\n",
    "        try:\n",
    "            images = convert_from_path(pdf_path)\n",
    "            text = \"\"\n",
    "            \n",
    "            for i, image in enumerate(images):\n",
    "                logging.info(f\"Processing page {i+1} of {len(images)}\")\n",
    "                text += pytesseract.image_to_string(image)\n",
    "                text += \"\\n\\n\"\n",
    "            \n",
    "            return text\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Local PDF processing failed: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def parse_transaction_data(self, text: str, user_id: int = 1) -> Dict[str, Any]:\n",
    "        logging.info(\"Parsing transaction data from extracted text\")\n",
    "        data = {\n",
    "            \"transaction_id\": str(uuid.uuid4()),\n",
    "            \"user_id\": user_id,\n",
    "            \"currency\": \"USD\",  # Default\n",
    "            \"description\": \"\",\n",
    "            \"category\": \"Other\",\n",
    "            \"deduction_rate\": 0.0,\n",
    "            \"max_limit\": 0,\n",
    "            \"tax_deductible\": False\n",
    "        }\n",
    "        \n",
    "        if not text:\n",
    "            logging.warning(\"No text provided for parsing\")\n",
    "            return data\n",
    "        \n",
    "        # Extract amount - look for dollar amounts\n",
    "        amount_patterns = [\n",
    "            r'(?:total|amount|price|due|payment)\\s*(?::|is|of)?\\s*\\$?\\s*(\\d+(?:,\\d+)*\\.\\d{2})',  # Total: $123.45\n",
    "            r'\\$\\s*(\\d+(?:,\\d+)*\\.\\d{2})',  # $123.45\n",
    "            r'(\\d+(?:,\\d+)*\\.\\d{2})\\s*(?:usd|dollars|eur|euro)'  # 123.45 USD\n",
    "        ]\n",
    "        \n",
    "        for pattern in amount_patterns:\n",
    "            amount_match = re.search(pattern, text, re.IGNORECASE)\n",
    "            if amount_match:\n",
    "                # Remove commas and convert to float\n",
    "                amount_str = amount_match.group(1).replace(',', '')\n",
    "                data[\"amount\"] = float(amount_str)\n",
    "                break\n",
    "        \n",
    "\n",
    "        date_patterns = [\n",
    "            r'\\b(\\d{4}-\\d{2}-\\d{2})\\b',  # YYYY-MM-DD\n",
    "            r'\\b(\\d{2}/\\d{2}/\\d{4})\\b',  # MM/DD/YYYY\n",
    "            r'\\b(\\d{2}-\\d{2}-\\d{4})\\b',  # MM-DD-YYYY\n",
    "            r'\\b(\\d{1,2}\\s+(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*\\s+\\d{4})\\b' \n",
    "        ]\n",
    "        \n",
    "        for pattern in date_patterns:\n",
    "            date_match = re.search(pattern, text, re.IGNORECASE)\n",
    "            if date_match:\n",
    "                data[\"date\"] = date_match.group(1)\n",
    "                break\n",
    "        \n",
    "        # Extract payment method\n",
    "        payment_methods = [\n",
    "            'Visa', 'MasterCard', 'Amex', 'American Express', 'Discover', 'Cash', \n",
    "            'Check', 'PayPal', 'Venmo', 'Apple Pay', 'Google Pay', 'Bank Transfer'\n",
    "        ]\n",
    "        \n",
    "        payment_pattern = '|'.join(payment_methods)\n",
    "        payment_match = re.search(f'\\\\b({payment_pattern})\\\\b', text, re.IGNORECASE)\n",
    "        if payment_match:\n",
    "            data[\"payment_method\"] = payment_match.group(1)\n",
    "        else:\n",
    "            data[\"payment_method\"] = \"Unknown\"\n",
    "        \n",
    "        # Extract merchant name\n",
    "        merchant_patterns = [\n",
    "            r'^([A-Z\\s]+)[\\n\\r]',  # First line in all caps\n",
    "            r'(?:merchant|vendor|store|shop|business):\\s*([^\\n\\r]+)',  # Labeled as merchant\n",
    "            r'(?:receipt from|purchased at|shop at):\\s*([^\\n\\r]+)'  # Context clues\n",
    "        ]\n",
    "        \n",
    "        for pattern in merchant_patterns:\n",
    "            merchant_match = re.search(pattern, text, re.IGNORECASE)\n",
    "            if merchant_match:\n",
    "                data[\"merchant\"] = merchant_match.group(1).strip()\n",
    "                break\n",
    "        \n",
    "        if \"merchant\" not in data or not data[\"merchant\"]:\n",
    "            # Fallback: use first non-empty line\n",
    "            lines = [line.strip() for line in text.split('\\n') if line.strip()]\n",
    "            if lines:\n",
    "                data[\"merchant\"] = lines[0]\n",
    "            else:\n",
    "                data[\"merchant\"] = \"Unknown\"\n",
    "        \n",
    "        # Extract description - use first few lines\n",
    "        lines = [line.strip() for line in text.split('\\n') if line.strip()]\n",
    "        if len(lines) > 1:\n",
    "            data[\"description\"] = ' '.join(lines[0:3])\n",
    "        \n",
    "        # Extract category based on keywords\n",
    "        text_lower = text.lower()\n",
    "        for policy in deduction_policies[\"deductions\"]:\n",
    "            category = policy[\"category\"]\n",
    "            keywords = self._get_category_keywords(category)\n",
    "            \n",
    "            for keyword in keywords:\n",
    "                if keyword.lower() in text_lower:\n",
    "                    data[\"category\"] = category\n",
    "                    data[\"deduction_rate\"] = policy[\"rate\"]\n",
    "                    data[\"max_limit\"] = policy[\"max_limit\"]\n",
    "                    data[\"tax_deductible\"] = policy[\"rate\"] > 0\n",
    "                    break\n",
    "            \n",
    "            if data[\"category\"] != \"Other\":\n",
    "                break\n",
    "        \n",
    "        # Extract currency\n",
    "        currency_match = re.search(r'\\b(USD|EUR|GBP|CAD|AUD|JPY)\\b', text, re.IGNORECASE)\n",
    "        if currency_match:\n",
    "            data[\"currency\"] = currency_match.group(1).upper()\n",
    "        \n",
    "        # Extract country\n",
    "        countries = ['USA', 'United States', 'Canada', 'UK', 'United Kingdom', \n",
    "                    'Germany', 'France', 'Italy', 'Spain', 'Japan', 'China']\n",
    "        country_pattern = '|'.join(countries)\n",
    "        country_match = re.search(f'\\\\b({country_pattern})\\\\b', text, re.IGNORECASE)\n",
    "        if country_match:\n",
    "            data[\"country\"] = country_match.group(1)\n",
    "        else:\n",
    "            data[\"country\"] = \"Unknown\"\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def _get_category_keywords(self, category: str) -> List[str]:\n",
    "        \"\"\"Get keywords associated with a specific expense category.\"\"\"\n",
    "        category_keywords = {\n",
    "            \"Home Office\": [\"home office\", \"desk\", \"chair\", \"office furniture\", \"filing cabinet\"],\n",
    "            \"Software & Subscriptions\": [\"software\", \"subscription\", \"license\", \"SaaS\", \"app\", \"service\"],\n",
    "            \"Freelancer Platform Fees\": [\"upwork\", \"fiverr\", \"freelancer\", \"platform fee\", \"service fee\"],\n",
    "            \"Work Equipment\": [\"laptop\", \"computer\", \"monitor\", \"keyboard\", \"mouse\", \"printer\", \"scanner\"],\n",
    "            \"Internet & Phone\": [\"internet\", \"phone\", \"mobile\", \"data plan\", \"wifi\", \"broadband\"],\n",
    "            \"Education & Training\": [\"course\", \"training\", \"workshop\", \"seminar\", \"conference\", \"book\", \"education\"],\n",
    "            \"Business Travel\": [\"flight\", \"hotel\", \"accommodation\", \"taxi\", \"uber\", \"airbnb\", \"travel\"],\n",
    "            \"Client Entertainment\": [\"restaurant\", \"meal\", \"entertainment\", \"client meeting\"],\n",
    "            \"Office Supplies\": [\"pen\", \"paper\", \"ink\", \"toner\", \"stapler\", \"notebook\", \"supplies\"],\n",
    "            \"Software & Tools\": [\"software\", \"tools\", \"application\", \"app\", \"program\"],\n",
    "            \"Meals & Entertainment\": [\"meal\", \"lunch\", \"dinner\", \"restaurant\", \"food\", \"coffee\"],\n",
    "            \"Rent & Utilities\": [\"rent\", \"lease\", \"utility\", \"electricity\", \"water\", \"gas\", \"heating\"],\n",
    "            \"Marketing & Advertising\": [\"marketing\", \"advertising\", \"promotion\", \"ad\", \"campaign\"],\n",
    "            \"Transportation\": [\"transportation\", \"bus\", \"train\", \"subway\", \"metro\", \"fuel\", \"gas\", \"parking\"],\n",
    "            \"Healthcare\": [\"healthcare\", \"medical\", \"doctor\", \"hospital\", \"prescription\", \"medicine\"],\n",
    "            \"Personal Shopping\": [\"clothing\", \"shoes\", \"accessory\", \"gift\", \"personal\"],\n",
    "            \"Groceries\": [\"grocery\", \"supermarket\", \"food store\", \"produce\"]\n",
    "        }\n",
    "        \n",
    "        return category_keywords.get(category, [category.lower()])\n",
    "    \n",
    "    def process_receipt(self, pdf_path: str, user_id: int = 1) -> Dict[str, Any]:\n",
    "\n",
    "        extracted_text = self.extract_text_from_pdf(pdf_path)\n",
    "        if not extracted_text:\n",
    "            logging.warning(f\"No text extracted from {pdf_path}\")\n",
    "            return {}\n",
    "            \n",
    "        transaction_data = self.parse_transaction_data(extracted_text, user_id)\n",
    "        return transaction_data\n",
    "    \n",
    "    def process_multiple_receipts(self, pdf_dir: str, user_id: int = 1) -> pd.DataFrame:\n",
    "    \n",
    "        transactions = []\n",
    "        \n",
    "        if not os.path.isdir(pdf_dir):\n",
    "            raise NotADirectoryError(f\"Directory not found: {pdf_dir}\")\n",
    "        \n",
    "        pdf_files = [f for f in os.listdir(pdf_dir) if f.lower().endswith('.pdf')]\n",
    "        logging.info(f\"Found {len(pdf_files)} PDF files in {pdf_dir}\")\n",
    "        \n",
    "        for pdf_file in pdf_files:\n",
    "            pdf_path = os.path.join(pdf_dir, pdf_file)\n",
    "            logging.info(f\"Processing {pdf_path}\")\n",
    "            \n",
    "            try:\n",
    "                transaction = self.process_receipt(pdf_path, user_id)\n",
    "                if transaction:\n",
    "                    transaction['filename'] = pdf_file\n",
    "                    transactions.append(transaction)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error processing {pdf_path}: {e}\")\n",
    "        \n",
    "        if not transactions:\n",
    "            logging.warning(\"No transactions processed successfully\")\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "        return pd.DataFrame(transactions)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Using local processing (no Google Cloud)\n",
    "    processor = ReceiptProcessor(use_google_cloud=False)\n",
    "    \n",
    "    #Process a single receipt\n",
    "    transaction = processor.process_receipt(\"../../data/forms/1040-NR.pdf\")\n",
    "    print(transaction)\n",
    "    \n",
    "    # Process multiple receipts\n",
    "    \n",
    "    # 2. Using Google Cloud Document AI (uncomment and provide your details)\n",
    "    processor = ReceiptProcessor(\n",
    "        use_google_cloud=True,\n",
    "        credentials_path=\"../../documentai.json\",\n",
    "        project_id=\"ai-finance-project-5e11b\",\n",
    "        processor_id=\"bf8ffc1bef694966\"\n",
    "     )\n",
    "    transaction = processor.process_receipt(\"../../data/forms/1040-NR.pdf\")\n",
    "    print(transaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "process_receipt() missing 1 required positional argument: 'credentials_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../data/forms/1040-NR.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m transaction \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_receipt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# No need for credentials_path\u001b[39;00m\n\u001b[0;32m      3\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([transaction])\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n",
      "\u001b[1;31mTypeError\u001b[0m: process_receipt() missing 1 required positional argument: 'credentials_path'"
     ]
    }
   ],
   "source": [
    "image_path = \"../../data/forms/1040-NR.pdf\"\n",
    "transaction = process_receipt(image_path)  # No need for credentials_path\n",
    "df = pd.DataFrame([transaction])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (3903784213.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[27], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(df)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "df = processor.process_multiple_receipts(\"path_to_receipts_dir\")\n",
    "    print(df)\n",
    "    df.to_csv(\"transactions.csv\", index=False)\n",
    "    \n",
    "    # 2. Using Google Cloud Document AI (uncomment and provide your details)\n",
    "    processor = ReceiptProcessor(\n",
    "        use_google_cloud=True,\n",
    "        credentials_path=\"path_to_credentials.json\",\n",
    "        project_id=\"your_project_id\",\n",
    "        processor_id=\"your_processor_id\"\n",
    "     )\n",
    "    transaction = processor.process_receipt(\"path_to_receipt.pdf\")\n",
    "    print(transaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "Unauthenticated",
     "evalue": "401 Request had invalid authentication credentials. Expected OAuth 2 access token, login cookie or other valid authentication credential. See https://developers.google.com/identity/sign-in/web/devconsole-project. [reason: \"ACCESS_TOKEN_EXPIRED\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"service\"\n  value: \"documentai.googleapis.com\"\n}\nmetadata {\n  key: \"method\"\n  value: \"google.cloud.documentai.v1.DocumentProcessorService.ProcessDocument\"\n}\n]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnauthenticated\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../data/forms/1040-NR.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m credentials_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../credentials.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m transaction \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_receipt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcredentials_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([transaction])\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n",
      "Cell \u001b[1;32mIn[19], line 94\u001b[0m, in \u001b[0;36mprocess_receipt\u001b[1;34m(pdf_path, credentials_path)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_receipt\u001b[39m(pdf_path, credentials_path):\n\u001b[0;32m     93\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Processes a receipt PDF and extracts structured transaction data.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 94\u001b[0m     extracted_text \u001b[38;5;241m=\u001b[39m \u001b[43mextract_text_from_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcredentials_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m     transaction_data \u001b[38;5;241m=\u001b[39m parse_transaction_data(extracted_text)\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m transaction_data\n",
      "Cell \u001b[1;32mIn[19], line 43\u001b[0m, in \u001b[0;36mextract_text_from_pdf\u001b[1;34m(pdf_path, credentials_path)\u001b[0m\n\u001b[0;32m     41\u001b[0m raw_document \u001b[38;5;241m=\u001b[39m documentai\u001b[38;5;241m.\u001b[39mRawDocument(content\u001b[38;5;241m=\u001b[39mpdf_content, mime_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     42\u001b[0m request \u001b[38;5;241m=\u001b[39m documentai\u001b[38;5;241m.\u001b[39mProcessRequest(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprojects/YOUR_PROJECT_ID/locations/us/processors/YOUR_PROCESSOR_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m, raw_document\u001b[38;5;241m=\u001b[39mraw_document)\n\u001b[1;32m---> 43\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_document\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdocument\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdocument\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\google\\cloud\\documentai_v1\\services\\document_processor_service\\client.py:948\u001b[0m, in \u001b[0;36mDocumentProcessorServiceClient.process_document\u001b[1;34m(self, request, name, retry, timeout, metadata)\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[0;32m    947\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m--> 948\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    949\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    950\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    951\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    952\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    953\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    955\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[1;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\google\\api_core\\retry\\retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[0;32m    292\u001b[0m )\n\u001b[1;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\google\\api_core\\retry\\retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\google\\api_core\\retry\\retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[1;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[0;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[0;32m    208\u001b[0m         error_list,\n\u001b[0;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[0;32m    210\u001b[0m         original_timeout,\n\u001b[0;32m    211\u001b[0m     )\n\u001b[1;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    214\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\google\\api_core\\retry\\retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[0;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\google\\api_core\\timeout.py:130\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         remaining_timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout\n\u001b[0;32m    128\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m remaining_timeout\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\google\\api_core\\grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mUnauthenticated\u001b[0m: 401 Request had invalid authentication credentials. Expected OAuth 2 access token, login cookie or other valid authentication credential. See https://developers.google.com/identity/sign-in/web/devconsole-project. [reason: \"ACCESS_TOKEN_EXPIRED\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"service\"\n  value: \"documentai.googleapis.com\"\n}\nmetadata {\n  key: \"method\"\n  value: \"google.cloud.documentai.v1.DocumentProcessorService.ProcessDocument\"\n}\n]"
     ]
    }
   ],
   "source": [
    "image_path = \"../../data/forms/1040-NR.pdf\"\n",
    "credentials_path = \"../../credentials.json\"\n",
    "transaction = process_receipt(image_path, credentials_path)\n",
    "df = pd.DataFrame([transaction])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing receipt1.jpg: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.\n",
      "Error processing receipt2.png: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 37\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m     36\u001b[0m image_files \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceipt1.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceipt2.png\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# List of receipt images\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m processed_data \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_receipts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_files\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Print structured results\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(json\u001b[38;5;241m.\u001b[39mdumps(processed_data, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n",
      "Cell \u001b[1;32mIn[5], line 18\u001b[0m, in \u001b[0;36mprocess_receipts\u001b[1;34m(image_paths)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Load deduction policy for categories\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../data/deduction_policy.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m---> 18\u001b[0m     deduction_policy \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Encode categorical values\u001b[39;00m\n\u001b[0;32m     21\u001b[0m label_encoders \u001b[38;5;241m=\u001b[39m {col: LabelEncoder() \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmerchant\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpayment_method\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n",
      "\u001b[1;31mNameError\u001b[0m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "def process_receipts(image_paths):\n",
    "    \"\"\"Process multiple receipt images and save structured data.\"\"\"\n",
    "    results = []\n",
    "\n",
    "    for image_path in image_paths:\n",
    "        try:\n",
    "            receipt_data = scan_receipt(image_path)  # OCR extraction\n",
    "            results.append(receipt_data)\n",
    "            print(f\"Processed {image_path}: {receipt_data}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image_path}: {e}\")\n",
    "\n",
    "    # Convert results to DataFrame\n",
    "    df = pd.DataFrame(results)\n",
    "\n",
    "    # Load deduction policy for categories\n",
    "    with open(\"../../data/deduction_policy.json\", \"r\") as f:\n",
    "        deduction_policy = json.load(f)\n",
    "\n",
    "    # Encode categorical values\n",
    "    label_encoders = {col: LabelEncoder() for col in [\"category\", \"merchant\", \"payment_method\"]}\n",
    "\n",
    "    for col in label_encoders:\n",
    "        df[col] = label_encoders[col].fit_transform(df[col])\n",
    "\n",
    "    # Normalize amount\n",
    "    df[\"amount\"] = (df[\"amount\"] - df[\"amount\"].min()) / (df[\"amount\"].max() - df[\"amount\"].min())\n",
    "\n",
    "    # Save to CSV\n",
    "    df.to_csv(\"receipts_data.csv\", index=False)\n",
    "    print(\"Receipts saved to receipts_data.csv âœ…\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "image_files = [\"receipt1.jpg\", \"receipt2.png\"]  # List of receipt images\n",
    "processed_data = process_receipts(image_files)\n",
    "\n",
    "# Print structured results\n",
    "print(json.dumps(processed_data, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
